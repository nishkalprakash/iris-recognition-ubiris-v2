{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIL462 Project Source Codes | 2024-2025 Fall | Context: Iris Recognition on UBIRIS.v2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: Sentetic Noise Addition (Image Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.66.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup and Library Imports\n",
    "\n",
    "The following code sets up the environment and imports the necessary libraries for the project:\n",
    "\n",
    "```python\n",
    "%pip install tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "\n",
    "1. **`%pip install tqdm`**\n",
    "   - A **magic command** in Jupyter Notebook to install the `tqdm` package directly within the notebook.\n",
    "   - `tqdm` is a Python library used to add progress bars to loops, which helps in tracking time-consuming tasks like image processing or training.\n",
    "\n",
    "2. **`import os`**\n",
    "   - The `os` module provides a way to interact with the operating system, including handling file paths, directories, and system-level operations.\n",
    "\n",
    "3. **`import cv2`**\n",
    "   - `cv2` is part of OpenCV (Open Source Computer Vision Library).\n",
    "   - It is used for image processing tasks, such as reading, writing, and manipulating images.\n",
    "\n",
    "4. **`import numpy as np`**\n",
    "   - `numpy` is a library for numerical operations on arrays and matrices, essential for handling image data, typically represented as arrays.\n",
    "\n",
    "5. **`from tqdm import tqdm`**\n",
    "   - Imports the `tqdm` function for displaying progress bars in loops, enhancing user experience by showing how far a process has progressed.\n",
    "\n",
    ">The purpose of tqdm is to provide a fast, extensible progress bar for Python loops and operations. It allows users to visually track the progress of time-consuming tasks, making it especially helpful for tasks involving large datasets or long-running computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_motion_blur(image, kernel_size=15):\n",
    "   \n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "    kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "    kernel = kernel / kernel_size\n",
    "    blurred = cv2.filter2D(image, -1, kernel)\n",
    "    return blurred\n",
    "\n",
    "\n",
    "def apply_low_light(image, gamma=0.3):\n",
    "    \"\"\"\n",
    "    Düşük ışık koşullarını simüle etmek için gamma düzeltmesi uygula.\n",
    "    \"\"\"\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    low_light_image = cv2.LUT(image, table)\n",
    "    return low_light_image\n",
    "\n",
    " \n",
    "input_folder = \"CLASSES_400_300\"  # Orijinal görüntülerin bulunduğu klasör\n",
    "output_folder = \"CLASSES_400_300_noised\"  # Gürültü eklenmiş görüntülerin kaydedileceği klasör\n",
    "\n",
    "# Çıkış klasörünü oluştur\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 116.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy images created successfully.\n",
      "Total number of images: 1\n",
      "Output folder: CLASSES_400_300_noised\n",
      "Filter application ratio (motion_blur): 0.0\n",
      "Filter application ratio (low_light): 1.0\n",
      "Filter application ratio (both): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize counters for different filters\n",
    "motion_blur_count = 0\n",
    "low_light_count = 0\n",
    "both_count = 0\n",
    "\n",
    "# Apply filters to all images in the input folder\n",
    "for image_name in tqdm(os.listdir(input_folder)):\n",
    "    image_path = os.path.join(input_folder, image_name)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        print(f\"Error reading image {image_path}\")\n",
    "        continue\n",
    "\n",
    "    noisy_image = image.copy()  # Create a copy of the image to apply filters\n",
    "\n",
    "    # Randomly choose a filter type with given probabilities\n",
    "    filters = np.random.choice([\"motion_blur\", \"low_light\", \"both\"], p=[0.4, 0.4, 0.2])\n",
    "\n",
    "    if filters == \"motion_blur\":\n",
    "        # Apply motion blur filter\n",
    "        noisy_image = add_motion_blur(noisy_image, kernel_size=15)\n",
    "        motion_blur_count += 1\n",
    "    elif filters == \"low_light\":\n",
    "        # Apply low-light filter\n",
    "        noisy_image = apply_low_light(noisy_image, gamma=0.4)\n",
    "        low_light_count += 1\n",
    "    else:  # both\n",
    "        # Apply both motion blur and low-light filters\n",
    "        noisy_image = add_motion_blur(noisy_image, kernel_size=15)\n",
    "        noisy_image = apply_low_light(noisy_image, gamma=0.4)\n",
    "        both_count += 1\n",
    "\n",
    "    # Save the filtered image to the output folder\n",
    "    output_path = os.path.join(output_folder, image_name)\n",
    "    cv2.imwrite(output_path, noisy_image)\n",
    "\n",
    "# Calculate the total number of images\n",
    "total_images = len(os.listdir(input_folder))\n",
    "\n",
    "# Print summary of the process\n",
    "print(\"Noisy images created successfully.\")\n",
    "print(\"Total number of images:\", total_images)\n",
    "print(\"Output folder:\", output_folder)\n",
    "print(\"Filter application ratio (motion_blur):\", motion_blur_count / total_images)\n",
    "print(\"Filter application ratio (low_light):\", low_light_count / total_images)\n",
    "print(\"Filter application ratio (both):\", both_count / total_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images (20%) successfully generated and saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "input_folder = r\"CLASSES_400_300\"\n",
    "output_folder = r\"CLASSES_400_300_augmented\"\n",
    "# r before the string denotes a raw string literal in python\n",
    "# it ensure that backslasher in the string are treate as literal charater\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Functions\n",
    "def rotate_image(image, label, number):\n",
    "    rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    output_path = os.path.join(output_folder, f\"{label}_rotate_{number}.jpg\")\n",
    "    cv2.imwrite(output_path, rotated_image)\n",
    "\n",
    "def flip_image(image, direction, label, number):\n",
    "    flipped_image = cv2.flip(image, direction)\n",
    "    output_path = os.path.join(output_folder, f\"{label}_flip_{direction}_{number}.jpg\")\n",
    "    cv2.imwrite(output_path, flipped_image)\n",
    "\n",
    "def add_light(image, gamma, label, number):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    brightened_image = cv2.LUT(image, table)\n",
    "    output_path = os.path.join(output_folder, f\"{label}_light_{gamma}_{number}.jpg\")\n",
    "    cv2.imwrite(output_path, brightened_image)\n",
    "\n",
    "# Data augmentation function\n",
    "def augment_images(input_folder, percentage):\n",
    "    \"\"\"\n",
    "    Augments images in the specified folder and generates new images based on the given percentage.\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input images.\n",
    "        percentage (float): Percentage of new images to generate.\n",
    "    Returns:\n",
    "        None\n",
    "    Process:\n",
    "        - Retrieves all .tiff files in the input folder.\n",
    "        - Calculates the target number of new images based on the total number of images.\n",
    "        - Performs data augmentation operations on each image:\n",
    "            - Rotates the image\n",
    "            - Flips the image\n",
    "            - Increases the brightness of the image\n",
    "            - Decreases the brightness of the image\n",
    "        - Stops once the specified percentage is reached.\n",
    "        - Prints the number and percentage of generated images.\n",
    "    \"\"\"\n",
    "    images = glob.glob(os.path.join(input_folder, \"*.tiff\"))\n",
    "    total_images = len(images)\n",
    "    target_count = int(total_images * (percentage / 100))  # Percentage target count\n",
    "    count = 0\n",
    "\n",
    "    for filepath in images:\n",
    "        if count >= target_count:  # Stop if the target percentage is reached\n",
    "            break\n",
    "\n",
    "        filename = os.path.basename(filepath)\n",
    "        image = cv2.imread(filepath)\n",
    "        label = os.path.splitext(filename)[0]  # File name label\n",
    "\n",
    "        # Data augmentation operations\n",
    "        rotate_image(image, label, count)\n",
    "        count += 1\n",
    "        if count >= target_count: break\n",
    "\n",
    "        flip_image(image, 0, label, count)\n",
    "        count += 1\n",
    "        if count >= target_count: break\n",
    "\n",
    "        add_light(image, 1.5, label, count)\n",
    "        count += 1\n",
    "        if count >= target_count: break\n",
    "\n",
    "        add_light(image, 0.7, label, count)\n",
    "        count += 1\n",
    "        if count >= target_count: break\n",
    "\n",
    "    print(f\"{count} images ({percentage}%) successfully generated and saved.\")\n",
    "\n",
    "# User-defined percentage N value\n",
    "N = 20  # For example, generate 20% of the total number of images\n",
    "augment_images(input_folder, N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3: Image Enhancement (DeepLearning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision scikit-image\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Tanımı\n",
    "class NoiseReductionDataset(Dataset):\n",
    "    def __init__(self, noisy_folder, original_folder, transform=None):\n",
    "        self.noisy_images = sorted(os.listdir(noisy_folder))\n",
    "        self.original_images = sorted(os.listdir(original_folder))\n",
    "        self.noisy_folder = noisy_folder\n",
    "        self.original_folder = original_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        noisy_path = os.path.join(self.noisy_folder, self.noisy_images[idx])\n",
    "        original_path = os.path.join(self.original_folder, self.original_images[idx])\n",
    "\n",
    "        noisy_image = cv2.imread(noisy_path, cv2.IMREAD_COLOR)\n",
    "        original_image = cv2.imread(original_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "            original_image = self.transform(original_image)\n",
    "\n",
    "        return noisy_image, original_image, os.path.basename(noisy_path)\n",
    "\n",
    "# Dataset Dönüşümleri\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset ve DataLoader\n",
    "noisy_folder = \"CLASSES_400_300_noised\"\n",
    "original_folder = \"CLASSES_400_300\"\n",
    "dataset = NoiseReductionDataset(noisy_folder, original_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Verileri Train/Validation/Test Split Yapma\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m))\n\u001b[0;32m      3\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.15\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m      4\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m-\u001b[39m train_size \u001b[38;5;241m-\u001b[39m val_size\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Verileri Train/Validation/Test Split Yapma\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DenseNet Encoder ve Karmaşık Decoder Modeli\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDenseNetModel\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(DenseNetModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# DenseNet Encoder ve Karmaşık Decoder Modeli\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.encoder = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1).features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()  # Renk bozulmalarını azaltmak için\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_size = x.size()[2:]  # Giriş boyutlarını kaydet\n",
    "        x = self.encoder(x)  # Encoder işlemi\n",
    "        x = self.decoder(x)  # Decoder işlemi\n",
    "        x = F.interpolate(x, size=original_size, mode=\"bilinear\", align_corners=False)  # Giriş boyutlarına geri döndür\n",
    "        return x\n",
    "\n",
    "# Kayıp Fonksiyonu (MSE + SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, data_range=1.0):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.data_range = data_range\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # MSE kaybı\n",
    "        mse_loss = self.mse(outputs, targets)\n",
    "        \n",
    "        # NumPy dizilerine dönüştürme\n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        targets_np = targets.cpu().numpy()\n",
    "        \n",
    "        # SSIM hesabı (data_range parametresi eklendi)\n",
    "        ssim_loss = np.mean([\n",
    "            1 - ssim(\n",
    "                targets_np[i].transpose(1, 2, 0),\n",
    "                outputs_np[i].transpose(1, 2, 0),\n",
    "                channel_axis=-1,\n",
    "                data_range=self.data_range\n",
    "            )\n",
    "            for i in range(len(outputs_np))\n",
    "        ])\n",
    "        \n",
    "        return mse_loss + 0.5 * ssim_loss\n",
    "\n",
    "# PSNR Hesaplama Fonksiyonu\n",
    "def calculate_psnr(mse):\n",
    "    return 20 * np.log10(1.0 / np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For using GPU - CUDA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Model, Loss Fonksiyonu ve Optimizasyon\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m DenseNetModel()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CombinedLoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# For using GPU - CUDA\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# Model, Loss Fonksiyonu ve Optimizasyon\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNetModel().to(device)\n",
    "criterion = CombinedLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "print(\"Torch Version:\", torch.__version__, \", CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Eğitim ve Metrik Kayıtları\n",
    "train_mse, val_mse = [], []\n",
    "train_ssim, val_ssim = [], []\n",
    "train_psnr, val_psnr = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m     epoch_train_mse, epoch_train_ssim, epoch_train_psnr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m noisy_images, original_images, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Eğitim Döngüsü\n",
    "num_epochs = 20\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_mse, epoch_train_ssim, epoch_train_psnr = 0, 0, 0\n",
    "\n",
    "    for noisy_images, original_images, _ in tqdm(train_loader):\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        original_images = original_images.to(device)\n",
    "\n",
    "        # Tahmin ve kayıp hesaplama\n",
    "        outputs = model(noisy_images)\n",
    "        loss = criterion(outputs, original_images)\n",
    "\n",
    "        # Geri yayılım\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrik hesaplama\n",
    "        epoch_train_mse += loss.item()\n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        original_np = original_images.cpu().numpy()\n",
    "\n",
    "        batch_ssim = np.mean([\n",
    "            ssim(original_np[i].transpose(1, 2, 0),\n",
    "                outputs_np[i].transpose(1, 2, 0),\n",
    "                channel_axis=-1,\n",
    "                data_range=1.0)\n",
    "            for i in range(len(outputs_np))\n",
    "        ])\n",
    "        epoch_train_ssim += batch_ssim\n",
    "\n",
    "        batch_psnr = calculate_psnr(loss.item())\n",
    "        epoch_train_psnr += batch_psnr\n",
    "\n",
    "    # Ortalama değerler\n",
    "    train_mse.append(epoch_train_mse / len(train_loader))\n",
    "    train_ssim.append(epoch_train_ssim / len(train_loader))\n",
    "    train_psnr.append(epoch_train_psnr / len(train_loader))\n",
    "\n",
    "    # Doğrulama Performansı\n",
    "    model.eval()\n",
    "    epoch_val_mse, epoch_val_ssim, epoch_val_psnr = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for noisy_images, original_images, _ in val_loader:\n",
    "            noisy_images = noisy_images.to(device)\n",
    "            original_images = original_images.to(device)\n",
    "\n",
    "            outputs = model(noisy_images)\n",
    "            loss = criterion(outputs, original_images)\n",
    "\n",
    "            epoch_val_mse += loss.item()\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            original_np = original_images.cpu().numpy()\n",
    "\n",
    "            batch_ssim = np.mean([\n",
    "                ssim(original_np[i].transpose(1, 2, 0),\n",
    "                    outputs_np[i].transpose(1, 2, 0),\n",
    "                    channel_axis=-1,\n",
    "                    data_range=1.0)  # Make sure your data is indeed scaled to [0,1]\n",
    "                for i in range(len(outputs_np))\n",
    "            ])\n",
    "            epoch_val_ssim += batch_ssim\n",
    "\n",
    "            batch_psnr = calculate_psnr(loss.item())\n",
    "            epoch_val_psnr += batch_psnr\n",
    "\n",
    "    val_mse.append(epoch_val_mse / len(val_loader))\n",
    "    val_ssim.append(epoch_val_ssim / len(val_loader))\n",
    "    val_psnr.append(epoch_val_psnr / len(val_loader))\n",
    "\n",
    "    scheduler.step(val_mse[-1])\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train MSE: {train_mse[-1]:.4f}, Val MSE: {val_mse[-1]:.4f}, \"\n",
    "          f\"Train SSIM: {train_ssim[-1]:.4f}, Val SSIM: {val_ssim[-1]:.4f}, \"\n",
    "          f\"Train PSNR: {train_psnr[-1]:.2f}, Val PSNR: {val_psnr[-1]:.2f}\")\n",
    "\n",
    "    if val_mse[-1] < best_val_loss:\n",
    "        best_val_loss = val_mse[-1]\n",
    "        torch.save(model.state_dict(), \"best_densenet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test Performansı\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_densenet_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m test_mse, test_ssim, test_psnr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Performansı\n",
    "model.load_state_dict(torch.load(\"best_densenet_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "test_mse, test_ssim, test_psnr = 0, 0, 0\n",
    "\n",
    "denoised_folder = \"CLASSES_400_300_denoised\"\n",
    "os.makedirs(denoised_folder, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for noisy_images, original_images, file_names in tqdm(test_loader):\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        original_images = original_images.to(device)\n",
    "\n",
    "        outputs = model(noisy_images)\n",
    "        loss = criterion(outputs, original_images)\n",
    "\n",
    "        test_mse += loss.item()\n",
    "        outputs_np = outputs.cpu().numpy()\n",
    "        original_np = original_images.cpu().numpy()\n",
    "\n",
    "        batch_ssim = np.mean([\n",
    "            ssim(original_np[i].transpose(1, 2, 0),\n",
    "                outputs_np[i].transpose(1, 2, 0),\n",
    "                channel_axis=-1,\n",
    "                data_range=1.0)\n",
    "            for i in range(len(outputs_np))\n",
    "        ])\n",
    "        test_ssim += batch_ssim\n",
    "\n",
    "        batch_psnr = calculate_psnr(loss.item())\n",
    "        test_psnr += batch_psnr\n",
    "\n",
    "        for i in range(outputs_np.shape[0]):\n",
    "            restored = np.clip((outputs_np[i].transpose(1, 2, 0) * 255), 0, 255).astype(np.uint8)\n",
    "            file_name = file_names[i]\n",
    "            output_path = os.path.join(denoised_folder, file_name)\n",
    "            cv2.imwrite(output_path, restored)\n",
    "\n",
    "test_mse /= len(test_loader)\n",
    "test_ssim /= len(test_loader)\n",
    "test_psnr /= len(test_loader)\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.4f}, Test SSIM: {test_ssim:.4f}, Test PSNR: {test_psnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Kayıp ve Metrik Grafiklerini Çiz\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_mse, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain MSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Kayıp ve Metrik Grafiklerini Çiz\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_mse, label=\"Train MSE\", marker=\"o\")\n",
    "plt.plot(val_mse, label=\"Validation MSE\", marker=\"o\")\n",
    "plt.title(\"Train and Validation MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_ssim, label=\"Train SSIM\", marker=\"o\")\n",
    "plt.plot(val_ssim, label=\"Validation SSIM\", marker=\"o\")\n",
    "plt.title(\"Train and Validation SSIM\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_psnr, label=\"Train PSNR\", marker=\"o\")\n",
    "plt.plot(val_psnr, label=\"Validation PSNR\", marker=\"o\")\n",
    "plt.title(\"Train and Validation PSNR\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"PSNR (dB)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"metrics_densenet.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
